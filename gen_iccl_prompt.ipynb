{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_math1 = load_dataset(\"cais/mmlu\", \"elementary_mathematics\")\n",
    "mmlu_math2 = load_dataset(\"cais/mmlu\", \"high_school_mathematics\")\n",
    "mmlu_math3 = load_dataset(\"cais/mmlu\", \"college_mathematics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Ms. Perez drove a total of 40 miles in 5 days. She drove the same number of miles each day. How many miles did Ms. Perez drive each day?', 'subject': 'elementary_mathematics', 'choices': ['5', '7', '8', '9'], 'answer': 2}\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset format\n",
    "print(mmlu_math1['test'][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ICCL prompts for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_iccl_single_example(example):\n",
    "    options = [\"0\", \"1\", \"2\", \"3\"]\n",
    "    question = example['question'] + \"\\nChoose the best answer from the following options:\" + \"\\n\" + \"\\n\".join([f\"{options[i]}. {option}\" for i, option in enumerate(example['choices'])]) + \"\\nAnswer: \"\n",
    "    return question, example['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multiple_iccl_prompts(topic_dataset, topic, n_prompts, base_dir=\"./\", exclude_hards=None):\n",
    "    \"\"\"\n",
    "    Generate multiple ICCL prompts for a single topic with all possible orderings of demonstrations.\n",
    "    Creates JSON files for each possible ordering and a baseline file with hard questions only.\n",
    "    \n",
    "    Args:\n",
    "        topic_dataset: Dictionary with test splits {\"easy\": easy_dataset, \"medium\": medium_dataset, \"hard\": hard_dataset}\n",
    "        topic: String representing the topic, e.g. \"math\"\n",
    "        n_prompts: Number of prompts to generate per ordering\n",
    "    \"\"\"\n",
    "    # Get all possible orderings of demonstrations (1=easy, 2=medium, 3=hard)\n",
    "            # randoms = list(permutations([1, 2, 3]))\n",
    "    # if \"easy\" not in topic_dataset:\n",
    "    #     orders = [[1,2,3], [1,3,2],[3,1,2]]\n",
    "    \n",
    "    # Create topic directory if it doesn't exist\n",
    "    topic_dir = os.path.join(base_dir, topic)\n",
    "    os.makedirs(topic_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert datasets to lists for easier random selection\n",
    "    if \"easy\" in topic_dataset:\n",
    "        easy_dataset = list(topic_dataset['easy']['test'])\n",
    "    medium_dataset = list(topic_dataset['medium']['test'])\n",
    "    hard_dataset = list(topic_dataset['hard']['test'])\n",
    "\n",
    "    randoms = list(permutations([1, 2, 3]))[1:] # exclude iccl\n",
    "\n",
    "\n",
    "    valid_hards = hard_dataset\n",
    "    # IF EXCLUDE HARDS\n",
    "    if exclude_hards:\n",
    "        valid_hards = [elt for elt in hard_dataset if elt[\"question\"] not in exclude_hards[topic]]\n",
    "        # print(\"TEST\", len(hard_dataset), len(valid_hards))\n",
    "    ######\n",
    "    \n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Select demonstration examples that will be used across all orderings\n",
    "        if \"easy\" in topic_dataset:\n",
    "            demo_easy = random.choice(easy_dataset)\n",
    "            demo_medium = random.choice(medium_dataset)\n",
    "        else:\n",
    "            demo_easy, demo_medium = random.sample(medium_dataset, 2)\n",
    "        demo_hard = random.choice(hard_dataset)\n",
    "        test_hard = random.choice(valid_hards)\n",
    "\n",
    "        orders = {\"iccl\": [1,2,3], \"random\": random.choice(randoms)} # choose random order \n",
    "        \n",
    "        # For each possible ordering\n",
    "        for order_str in orders:\n",
    "            # Create prompts dict if it doesn't exist for this ordering\n",
    "            order = orders[order_str]\n",
    "            \n",
    "            filename = f\"{topic}_{order_str}_examples.json\"\n",
    "            filepath = os.path.join(topic_dir, filename)\n",
    "            \n",
    "            try:\n",
    "                with open(filepath, 'r') as f:\n",
    "                    prompts = json.load(f)\n",
    "            except FileNotFoundError:\n",
    "                prompts = {}\n",
    "            \n",
    "            # Map order numbers to actual examples\n",
    "            order_to_example = {\n",
    "                1: (demo_easy, \"easy\"),\n",
    "                2: (demo_medium, \"medium\"),\n",
    "                3: (demo_hard, \"hard\")\n",
    "            }\n",
    "            \n",
    "            # Generate demonstrations in specified order\n",
    "            demonstrations = []\n",
    "            for difficulty in order:\n",
    "                example, level = order_to_example[difficulty]\n",
    "                q, a = gen_iccl_single_example(example)\n",
    "                demonstrations.append((q, a, level))\n",
    "            \n",
    "            # Generate test question\n",
    "            test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "            \n",
    "            # Build prompt\n",
    "            prompt = \"\"\n",
    "            for demo_q, demo_a, level in demonstrations:\n",
    "                prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "            prompt += f\"{test_question}\"\n",
    "            \n",
    "            prompts[str(prompt_idx)] = {\n",
    "                \"question\": prompt,\n",
    "                \"answer\": test_answer,\n",
    "            }\n",
    "            \n",
    "            # Write prompts to JSON file\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(prompts, f, indent=4)\n",
    "            \n",
    "    ### HARD BASELINE: Generate baseline of hard-only prompts\n",
    "    baseline_filename = f\"{topic}_hard_baseline_iccl_examples.json\"\n",
    "    baseline_filepath = os.path.join(topic_dir, baseline_filename)\n",
    "    baseline_prompts = {}\n",
    "    \n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Select two different hard questions for baseline\n",
    "        hard1, hard2 = random.sample(hard_dataset, 2)\n",
    "        q1, a1 = gen_iccl_single_example(hard1)\n",
    "        q2, a2 = gen_iccl_single_example(hard2)\n",
    "        \n",
    "        baseline_prompts[str(prompt_idx)] = {\n",
    "            \"question\": f\"{q1}{a1}\\n\\n{q2}\",\n",
    "            \"answer\": a2,\n",
    "        }\n",
    "    \n",
    "    #### Write baseline prompts to JSON file\n",
    "    with open(baseline_filepath, 'w') as f:\n",
    "        json.dump(baseline_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 100 55\n"
     ]
    }
   ],
   "source": [
    "n_prompts = 50\n",
    "\n",
    "topics = [\"biology\", \"chemistry\", \"computer_science\", \"physics\"]\n",
    "nicknames = {\"biology\": \"bio\", \"chemistry\":\"chem\", \"computer_science\": \"cs\", \"physics\": \"phys\"}\n",
    "\n",
    "exclude_hards = exclude_questions()\n",
    "\n",
    "gen_multiple_iccl_prompts({\"easy\": mmlu_math1, \"medium\": mmlu_math2, \"hard\": mmlu_math3}, \"math\", 50, \"./prompts/finetuned_prompts/\", exclude_hards)\n",
    "\n",
    "# for topic in topics[1:]:\n",
    "#     mmlu_1 = load_dataset(\"cais/mmlu\", f\"high_school_{topic}\")\n",
    "#     mmlu_2 = load_dataset(\"cais/mmlu\", f\"college_{topic}\")\n",
    "    \n",
    "#     topic_dataset = {\"medium\": mmlu_1, \"hard\": mmlu_2}\n",
    "#     gen_multiple_iccl_prompts(topic_dataset, nicknames[topic], 50, \"./prompts/finetuned_prompts/\", exclude_hards)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "def exclude_questions(base_path='./final_train'):\n",
    "    # List of subjects\n",
    "    subjects = ['bio', 'chem', 'cs', 'math', 'phys']\n",
    "    \n",
    "    # Dictionary to store hard problems for each subject\n",
    "    exclude_hards = {}\n",
    "    \n",
    "    # Iterate through each subject\n",
    "    for subject in subjects:\n",
    "        # Construct the filename for subject-specific hard problems\n",
    "        hard_filename = f'{subject}_test.json'\n",
    "        hard_filepath = os.path.join(base_path, subject, hard_filename)\n",
    "        \n",
    "        # Read the hard problems JSON file\n",
    "        try:\n",
    "            with open(hard_filepath, 'r') as f:\n",
    "                original_list = json.load(f)\n",
    "            \n",
    "            # Extract first line of each question\n",
    "            modified_list = [\n",
    "                elt[\"question\"].split(\"\\n\")[0] for elt in original_list\n",
    "            ]\n",
    "\n",
    "            # print(\"Test\", elt[\"question\"].split(\"\\n\"))\n",
    "            # return 0\n",
    "            \n",
    "            # Store the modified list in the dictionary\n",
    "            exclude_hards[subject] = modified_list\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {hard_filepath} not found. Skipping for {subject}.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Unable to parse {hard_filepath}. Ensure it's a valid JSON list.\")\n",
    "    \n",
    "    return exclude_hards\n",
    "\n",
    "res = exclude_questions()\n",
    "\n",
    "print(len(res[\"bio\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train/test split for maggie/jennifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def split_and_save_datasets(topic_dataset, topic, output_dir: str = \"./\"):\n",
    "    \"\"\"\n",
    "    Split datasets into train and test sets and save them as JSON files.\n",
    "    \n",
    "    Args:\n",
    "        topic_dataset: Dictionary with 'medium' and 'hard' datasets\n",
    "        output_dir: Directory to save the JSON files\n",
    "    \"\"\"\n",
    "    train_dir = os.path.join(output_dir, \"train\", topic)\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Ensure we're working with the train split if it's a DatasetDict\n",
    "    medium_data = topic_dataset['medium']['test']\n",
    "    hard_data = topic_dataset['hard']['test']\n",
    "    \n",
    "    # Convert to list of dictionaries for easier handling\n",
    "    medium_list = medium_data.to_list()\n",
    "    hard_list = hard_data.to_list()\n",
    "    \n",
    "    # Randomly shuffle the data\n",
    "    random.shuffle(medium_list)\n",
    "    random.shuffle(hard_list)\n",
    "    \n",
    "    # Split the datasets\n",
    "    train_easy = medium_list[:50]\n",
    "    train_medium = medium_list[50:100]  # First 100 for medium training\n",
    "    train_hard = hard_list[:50]       # First 50 for hard training\n",
    "    test_hard = hard_list[50:100]     # Next 50 for hard testing\n",
    "    \n",
    "    ### JUST FOR MATH - comment out otherwise\n",
    "    easy_data = topic_dataset['easy']['test']\n",
    "    easy_list = easy_data.to_list()\n",
    "    random.shuffle(easy_list)\n",
    "    train_easy = easy_list[:50] # update EASY\n",
    "\n",
    "    # Create combined training set\n",
    "    combined_train = deepcopy(train_easy) + deepcopy(train_medium) + deepcopy(train_hard)\n",
    "    shuffled_train = deepcopy(combined_train)\n",
    "    random.shuffle(shuffled_train)\n",
    "   \n",
    "    # Save training files\n",
    "    train_files = {\n",
    "        'easy.json': train_easy,\n",
    "        'medium.json': train_medium,\n",
    "        'hard.json': train_hard,\n",
    "        'shuffled.json': shuffled_train,\n",
    "        'concat.json': combined_train\n",
    "    }\n",
    "    \n",
    "    test_files = {\n",
    "        f'{topic}.json': test_hard,\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    datasets = ((train_files, train_dir), (test_files, test_dir))\n",
    "\n",
    "    for dataset, dataset_dir in datasets:\n",
    "        \n",
    "        \n",
    "        for filename, data in dataset.items():\n",
    "            reformatted_data = []\n",
    "            for elt in data:\n",
    "                test_question, test_answer = gen_iccl_single_example(elt)\n",
    "                reformatted_data.append({\"question\": test_question, \"answer\": test_answer})\n",
    "    \n",
    "            data = reformatted_data\n",
    "            \n",
    "            \n",
    "            full_path = os.path.join(dataset_dir, filename)\n",
    "            with open(full_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Saved {len(data)} examples to {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 examples to ./prompts/maggie_jennifer/train/chem/easy.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/chem/medium.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/chem/hard.json\n",
      "Saved 150 examples to ./prompts/maggie_jennifer/train/chem/shuffled.json\n",
      "Saved 150 examples to ./prompts/maggie_jennifer/train/chem/concat.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/test/chem.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/cs/easy.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/cs/medium.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/cs/hard.json\n",
      "Saved 150 examples to ./prompts/maggie_jennifer/train/cs/shuffled.json\n",
      "Saved 150 examples to ./prompts/maggie_jennifer/train/cs/concat.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/test/cs.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/phys/easy.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/phys/medium.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/train/phys/hard.json\n",
      "Saved 150 examples to ./prompts/maggie_jennifer/train/phys/shuffled.json\n",
      "Saved 150 examples to ./prompts/maggie_jennifer/train/phys/concat.json\n",
      "Saved 50 examples to ./prompts/maggie_jennifer/test/phys.json\n"
     ]
    }
   ],
   "source": [
    "n_prompts = 50\n",
    "\n",
    "topics = [\"biology\", \"chemistry\", \"computer_science\", \"physics\"]\n",
    "nicknames = {\"biology\": \"bio\", \"chemistry\":\"chem\", \"computer_science\": \"cs\", \"physics\": \"phys\"}\n",
    "\n",
    "# Create directory structure\n",
    "base_dir = \"./prompts/maggie_jennifer\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for topic in topics[1:]:\n",
    "    mmlu_1 = load_dataset(\"cais/mmlu\", f\"high_school_{topic}\")\n",
    "    mmlu_2 = load_dataset(\"cais/mmlu\", f\"college_{topic}\")\n",
    "    \n",
    "    topic_dataset = {\"medium\": mmlu_1, \"hard\": mmlu_2}\n",
    "    split_and_save_datasets(topic_dataset, nicknames[topic], base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 examples to ./maggie_jennifer/train/math/easy.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/math/medium.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/math/hard.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/math/shuffled.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/math/concat.json\n",
      "Saved 50 examples to ./maggie_jennifer/test/math.json\n"
     ]
    }
   ],
   "source": [
    "topic = \"mathematics\"\n",
    "mmlu_0 = load_dataset(\"cais/mmlu\", f\"elementary_{topic}\")\n",
    "mmlu_1 = load_dataset(\"cais/mmlu\", f\"high_school_{topic}\")\n",
    "mmlu_2 = load_dataset(\"cais/mmlu\", f\"college_{topic}\")\n",
    "\n",
    "split_and_save_datasets({\"easy\": mmlu_0, \"medium\": mmlu_1, \"hard\": mmlu_2}, \"math\", \"./prompts/maggie_jennifer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multiple_iccl_prompts(topic_datasets, n_prompts):\n",
    "    \"\"\"\n",
    "    Generate multiple ICCL prompts for each topic with all possible orderings of easy/medium/hard demonstrations.\n",
    "    Creates 6 JSON files per topic (one for each possible ordering).\n",
    "    \n",
    "    Args:\n",
    "        topic_datasets: Dictionary of dataset triples {\"math\": [easy1, medium1, hard1], \"english\": [easy2, medium2, hard2], ...}\n",
    "                       where each dataset has a 'test' split\n",
    "        n_prompts: Number of prompts to generate per ordering\n",
    "    \"\"\"\n",
    "    # Get all possible orderings of demonstrations (1=easy, 2=medium, 3=hard)\n",
    "    orders = list(permutations([1, 2, 3]))\n",
    "    \n",
    "    for topic in topic_datasets:\n",
    "        # Create topic directory if it doesn't exist\n",
    "        os.makedirs(topic, exist_ok=True)\n",
    "        \n",
    "        easy_dataset, medium_dataset, hard_dataset = topic_datasets[topic]\n",
    "        \n",
    "        # Convert datasets to lists for easier random selection\n",
    "        easy_examples = list(easy_dataset['test'])\n",
    "        medium_examples = list(medium_dataset['test'])\n",
    "        hard_examples = list(hard_dataset['test'])\n",
    "        \n",
    "        # Track used hard examples across all orderings\n",
    "        used_hard_indices = set()\n",
    "        \n",
    "        # Generate the specified number of prompts\n",
    "        for prompt_idx in range(n_prompts):\n",
    "            # Select unused hard example for testing\n",
    "            available_hard_indices = [i for i in range(len(hard_examples)) if i not in used_hard_indices]\n",
    "            if not available_hard_indices:\n",
    "                raise ValueError(f\"Not enough unique hard examples available for topic {topic}\")\n",
    "            \n",
    "            test_hard_index = random.choice(available_hard_indices)\n",
    "            test_hard = hard_examples[test_hard_index]\n",
    "            used_hard_indices.add(test_hard_index)\n",
    "            \n",
    "            # Select demonstration examples\n",
    "            demo_easy = random.choice(easy_examples)\n",
    "            demo_medium = random.choice(medium_examples)\n",
    "            demo_hard = random.choice([ex for i, ex in enumerate(hard_examples) if i not in used_hard_indices])\n",
    "            \n",
    "            # For each possible ordering\n",
    "            for order in orders:\n",
    "                # Create prompts dict if it doesn't exist for this ordering\n",
    "                order_str = ''.join(str(x) for x in order)\n",
    "                filename = f\"{topic}_{order_str}_iccl_examples.json\"\n",
    "                filepath = os.path.join(topic, filename)\n",
    "                \n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        prompts = json.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    prompts = {}\n",
    "                \n",
    "                # Map order numbers to actual examples\n",
    "                order_to_example = {\n",
    "                    1: (demo_easy, \"easy\"),\n",
    "                    2: (demo_medium, \"medium\"),\n",
    "                    3: (demo_hard, \"hard\")\n",
    "                }\n",
    "                \n",
    "                # Generate demonstrations in specified order\n",
    "                demonstrations = []\n",
    "                for difficulty in order:\n",
    "                    example, level = order_to_example[difficulty]\n",
    "                    q, a = gen_iccl_single_example(example)\n",
    "                    demonstrations.append((q, a, level))\n",
    "                \n",
    "                # Generate test question\n",
    "                test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "                \n",
    "                # Build prompt\n",
    "                prompt = \"\"\n",
    "                for demo_q, demo_a, level in demonstrations:\n",
    "                    prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "                prompt += f\"{test_question}\"\n",
    "                \n",
    "                prompts[str(prompt_idx)] = {\n",
    "                    \"question\": prompt,\n",
    "                    \"answer\": test_answer,\n",
    "                }\n",
    "                \n",
    "                # Write prompts to JSON file\n",
    "                with open(filepath, 'w') as f:\n",
    "                    json.dump(prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_iccl_prompt(topic_datasets):\n",
    "    \"\"\"\n",
    "    Generate a random ICCL prompt with demonstrations from easy/medium/hard difficulty,\n",
    "    followed by a hard test question.\n",
    "    \n",
    "    Args:\n",
    "        topic_datasets: Dictionary of dataset triples {\"math\": [easy1, medium1, hard1], \"english\": [easy2, medium2, hard2], ...}\n",
    "                       where each dataset has a 'test' split\n",
    "    \n",
    "    Returns:\n",
    "        str: prompt_string\n",
    "    \"\"\"\n",
    "    # Randomly select a topic\n",
    "    topic = random.choice(list(topic_datasets.keys()))\n",
    "    easy_dataset, medium_dataset, hard_dataset = topic_datasets[topic]\n",
    "    \n",
    "    # Convert datasets to lists for easier random selection\n",
    "    easy_examples = list(easy_dataset['test'])\n",
    "    medium_examples = list(medium_dataset['test'])\n",
    "    hard_examples = list(hard_dataset['test'])\n",
    "    \n",
    "    # Select demonstration examples\n",
    "    demo_easy = random.choice(easy_examples)\n",
    "    demo_medium = random.choice(medium_examples)\n",
    "    demo_hard = random.choice(hard_examples)\n",
    "    \n",
    "    # Select test example from remaining hard examples\n",
    "    # Ensure we don't use the same hard example as in demonstration\n",
    "    remaining_hard = [ex for ex in hard_examples if ex != demo_hard]\n",
    "    if not remaining_hard:\n",
    "        raise ValueError(\"Not enough unique hard examples available\")\n",
    "    test_hard = random.choice(remaining_hard)\n",
    "    \n",
    "    # Generate demonstrations\n",
    "    demonstrations = [\n",
    "        gen_iccl_single_example(demo_easy),\n",
    "        gen_iccl_single_example(demo_medium),\n",
    "        gen_iccl_single_example(demo_hard)\n",
    "    ]\n",
    "    \n",
    "    # Generate test question, won't return test_answer\n",
    "    test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = \"\"\n",
    "    for demo_q, demo_a in demonstrations:\n",
    "        prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "    prompt += f\"{test_question}\"\n",
    "    \n",
    "    return prompt, test_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gwen wrote the number pattern below on a piece of paper. 1, 5, 9, 13 What are the next two terms in Gwenâ€™s pattern?\n",
      "Choose the best answer from the following options:\n",
      "0. 15, 17\n",
      "1. 15, 19\n",
      "2. 17, 19\n",
      "3. 17, 21\n",
      "Answer: 3\n",
      "\n",
      "The area bounded by the parabola y = x^2 and the lines y = 1 and y = 9 equals\n",
      "Choose the best answer from the following options:\n",
      "0. 8\n",
      "1. 84/3\n",
      "2. 64\\sqrt{2}/3\n",
      "3. 104/3\n",
      "Answer: 3\n",
      "\n",
      "What is the greatest possible area of a triangular region with one vertex at the center of a circle of radius 1 and the other two vertices on the circle?\n",
      "Choose the best answer from the following options:\n",
      "0. 1/2\n",
      "1. 1\n",
      "2. sqrt(2)\n",
      "3. pi\n",
      "Answer: 0\n",
      "\n",
      "Sofia and Tess will each randomly choose one of the 10 integers from 1 to 10. What is the probability that neither integer chosen will be the square of the other?\n",
      "Choose the best answer from the following options:\n",
      "0. 0.64\n",
      "1. 0.72\n",
      "2. 0.81\n",
      "3. 0.95\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt, answer = gen_random_iccl_prompt({\"math\": [mmlu_math1, mmlu_math2, mmlu_math3]})\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_multiple_iccl_prompts({\"math\": [mmlu_math1, mmlu_math2, mmlu_math3]}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test on math subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_iccl_single_example(example):\n",
    "    options = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    question = example['question'] + \"\\nChoose the best answer from the following options:\" + \"\\n\" + \"\\n\".join([f\"{options[i]}. {option}\" for i, option in enumerate(example['choices'])]) + \"\\nAnswer: \"\n",
    "    return question, example['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the value of p in 24 = 2p?\n",
      "Choose the best answer from the following options:\n",
      "A. p = 4\n",
      "B. p = 8\n",
      "C. p = 12\n",
      "D. p = 24\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(gen_iccl_single_example(mmlu_math1['test'][0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_all_iccl_prompts(easy_dataset, medium_dataset, hard_dataset, n_prompts, topic):\n",
    "    try:\n",
    "        with open(\"iccl_prompts.json\", 'r') as f:\n",
    "            iccl_prompts = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        iccl_prompts = {}\n",
    "    if topic not in iccl_prompts:\n",
    "        iccl_prompts[topic] = {}\n",
    "    \n",
    "    # Convert datasets to lists for easier shuffling & tracking\n",
    "    easy_examples = list(easy_dataset['test'])\n",
    "    medium_examples = list(medium_dataset['test'])\n",
    "    hard_examples = list(hard_dataset['test'])\n",
    "\n",
    "    # Use indices to track used hard examples\n",
    "    used_hard_indices = set()\n",
    "    prompts = []\n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Curriculum examples for demonstrations\n",
    "        demo_easy = random.choice(easy_examples)\n",
    "        demo_medium = random.choice(medium_examples)\n",
    "        demo_hard_index = random.choice([i for i in range(len(hard_examples)) if i not in used_hard_indices])\n",
    "        demo_hard = hard_examples[demo_hard_index]\n",
    "\n",
    "        # Can't use hard example that appeared in demonstration for testing\n",
    "        used_hard_indices.add(demo_hard_index)\n",
    "        available_hard_indices = [i for i in range(len(hard_examples)) if i not in used_hard_indices]\n",
    "        if not available_hard_indices:\n",
    "            raise ValueError(\"Not enough unique hard examples available\")\n",
    "        test_hard_index = random.choice(available_hard_indices)\n",
    "        test_hard = hard_examples[test_hard_index]\n",
    "        used_hard_indices.add(test_hard_index)\n",
    "\n",
    "        demonstrations = [\n",
    "            gen_iccl_single_example(demo_easy),\n",
    "            gen_iccl_single_example(demo_medium),\n",
    "            gen_iccl_single_example(demo_hard)\n",
    "        ]\n",
    "        test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "\n",
    "        prompt = \"\"\n",
    "        for demo_q, demo_a in demonstrations:\n",
    "            prompt += f\"{demo_q}\" + str(demo_a) + \"\\n\\n\"\n",
    "        prompt += f\"{test_question}\"\n",
    "\n",
    "        iccl_prompts[topic][f\"{prompt_idx}\"] = {\n",
    "            \"question\": prompt,\n",
    "            \"answer\": test_answer\n",
    "        }\n",
    "\n",
    "    # Write the updated JSON back to the file\n",
    "    with open(\"iccl_prompts.json\", 'w') as f:\n",
    "        json.dump(iccl_prompts, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_all_iccl_prompts(mmlu_math1, mmlu_math2, mmlu_math3, int(len(mmlu_math3['test']) // 2), \"math\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
