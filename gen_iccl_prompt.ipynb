{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on math subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a631274ea64bd0bebf93756354451f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/53.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a57e7fcf30843868de7ab8b9de40eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/138k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88d62de288c448b8c1b7e72aea43078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/41.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16958ef6dd740248ceba42c392bcd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/9.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac37d20d58d49ae90c58ee61fa0f479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fb4d8d559e446e9bb740cbe52f7143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6b0a512dbb415793c9cc9e623eb15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/41 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94bdd2a668c4a3ebe73ce4f32f0d5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30137d29fbd14d3cab3e3729bfb07e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/33.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20e68d02240441ab707061719ca8cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/6.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba616bc532db4de1995499b16fd2706c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/4.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dffab16d4dd459186ef8003b5f238f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d717a08a1944e8a38b3cad0455ebfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70512c2695b4883adbe64ba8238e000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d16cdf462b5458d89ce256e8caaefe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/16.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3499cb7ec30c4757899da7e9fb8dd045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/5.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caebacddc7424deead99bf3b908790b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff7a5192cb6486387bbf2ede78f083f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa87169a8484e8183cc7af3da6b4090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9311582657d546188496f0a0116135f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mmlu_math1 = load_dataset(\"cais/mmlu\", \"elementary_mathematics\")\n",
    "mmlu_math2 = load_dataset(\"cais/mmlu\", \"high_school_mathematics\")\n",
    "mmlu_math3 = load_dataset(\"cais/mmlu\", \"college_mathematics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Ms. Perez drove a total of 40 miles in 5 days. She drove the same number of miles each day. How many miles did Ms. Perez drive each day?', 'subject': 'elementary_mathematics', 'choices': ['5', '7', '8', '9'], 'answer': 2}\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset format\n",
    "print(mmlu_math1['test'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_iccl_single_example(example):\n",
    "    question = example['question'] + \"\\nChoose the best answer from the following options:\" + \"\\n\" + \"\\n\".join([f\"{i}. {option}\" for i, option in enumerate(example['choices'])]) + \"\\nAnswer: \"\n",
    "    return question, example['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the value of p in 24 = 2p?\n",
      "Choose the best answer from the following options:\n",
      "0. p = 4\n",
      "1. p = 8\n",
      "2. p = 12\n",
      "3. p = 24\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(gen_iccl_single_example(mmlu_math1['test'][0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_all_iccl_prompts(easy_dataset, medium_dataset, hard_dataset, n_prompts, topic):\n",
    "    try:\n",
    "        with open(\"iccl_prompts.json\", 'r') as f:\n",
    "            iccl_prompts = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        iccl_prompts = {}\n",
    "    if topic not in iccl_prompts:\n",
    "        iccl_prompts[topic] = {}\n",
    "    \n",
    "    # Convert datasets to lists for easier shuffling & tracking\n",
    "    easy_examples = list(easy_dataset['test'])\n",
    "    medium_examples = list(medium_dataset['test'])\n",
    "    hard_examples = list(hard_dataset['test'])\n",
    "\n",
    "    # Use indices to track used hard examples\n",
    "    used_hard_indices = set()\n",
    "    prompts = []\n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Curriculum examples for demonstrations\n",
    "        demo_easy = random.choice(easy_examples)\n",
    "        demo_medium = random.choice(medium_examples)\n",
    "        demo_hard_index = random.choice([i for i in range(len(hard_examples)) if i not in used_hard_indices])\n",
    "        demo_hard = hard_examples[demo_hard_index]\n",
    "\n",
    "        # Can't use hard example that appeared in demonstration for testing\n",
    "        used_hard_indices.add(demo_hard_index)\n",
    "        available_hard_indices = [i for i in range(len(hard_examples)) if i not in used_hard_indices]\n",
    "        if not available_hard_indices:\n",
    "            raise ValueError(\"Not enough unique hard examples available\")\n",
    "        test_hard_index = random.choice(available_hard_indices)\n",
    "        test_hard = hard_examples[test_hard_index]\n",
    "        used_hard_indices.add(test_hard_index)\n",
    "\n",
    "        demonstrations = [\n",
    "            gen_iccl_single_example(demo_easy),\n",
    "            gen_iccl_single_example(demo_medium),\n",
    "            gen_iccl_single_example(demo_hard)\n",
    "        ]\n",
    "        test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "\n",
    "        prompt = \"\"\n",
    "        for demo_q, demo_a in demonstrations:\n",
    "            prompt += f\"{demo_q}\" + str(demo_a) + \"\\n\\n\"\n",
    "        prompt += f\"{test_question}\"\n",
    "\n",
    "        iccl_prompts[topic][f\"{prompt_idx}\"] = {\n",
    "            \"question\": prompt,\n",
    "            \"answer\": test_answer\n",
    "        }\n",
    "\n",
    "    # Write the updated JSON back to the file\n",
    "    with open(\"iccl_prompts.json\", 'w') as f:\n",
    "        json.dump(iccl_prompts, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_all_iccl_prompts(mmlu_math1, mmlu_math2, mmlu_math3, int(len(mmlu_math3['test']) // 2), \"math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ICCL prompts for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_iccl_prompt(topic_datasets):\n",
    "    \"\"\"\n",
    "    Generate a random ICCL prompt with demonstrations from easy/medium/hard difficulty,\n",
    "    followed by a hard test question.\n",
    "    \n",
    "    Args:\n",
    "        topic_datasets: Dictionary of dataset triples {\"math\": [easy1, medium1, hard1], \"english\": [easy2, medium2, hard2], ...}\n",
    "                       where each dataset has a 'test' split\n",
    "    \n",
    "    Returns:\n",
    "        str: prompt_string\n",
    "    \"\"\"\n",
    "    # Randomly select a topic\n",
    "    topic = random.choice(list(topic_datasets.keys()))\n",
    "    easy_dataset, medium_dataset, hard_dataset = topic_datasets[topic]\n",
    "    \n",
    "    # Convert datasets to lists for easier random selection\n",
    "    easy_examples = list(easy_dataset['test'])\n",
    "    medium_examples = list(medium_dataset['test'])\n",
    "    hard_examples = list(hard_dataset['test'])\n",
    "    \n",
    "    # Select demonstration examples\n",
    "    demo_easy = random.choice(easy_examples)\n",
    "    demo_medium = random.choice(medium_examples)\n",
    "    demo_hard = random.choice(hard_examples)\n",
    "    \n",
    "    # Select test example from remaining hard examples\n",
    "    # Ensure we don't use the same hard example as in demonstration\n",
    "    remaining_hard = [ex for ex in hard_examples if ex != demo_hard]\n",
    "    if not remaining_hard:\n",
    "        raise ValueError(\"Not enough unique hard examples available\")\n",
    "    test_hard = random.choice(remaining_hard)\n",
    "    \n",
    "    # Generate demonstrations\n",
    "    demonstrations = [\n",
    "        gen_iccl_single_example(demo_easy),\n",
    "        gen_iccl_single_example(demo_medium),\n",
    "        gen_iccl_single_example(demo_hard)\n",
    "    ]\n",
    "    \n",
    "    # Generate test question, won't return test_answer\n",
    "    test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = \"\"\n",
    "    for demo_q, demo_a in demonstrations:\n",
    "        prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "    prompt += f\"{test_question}\"\n",
    "    \n",
    "    return prompt, test_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gwen wrote the number pattern below on a piece of paper. 1, 5, 9, 13 What are the next two terms in Gwenâ€™s pattern?\n",
      "Choose the best answer from the following options:\n",
      "0. 15, 17\n",
      "1. 15, 19\n",
      "2. 17, 19\n",
      "3. 17, 21\n",
      "Answer: 3\n",
      "\n",
      "The area bounded by the parabola y = x^2 and the lines y = 1 and y = 9 equals\n",
      "Choose the best answer from the following options:\n",
      "0. 8\n",
      "1. 84/3\n",
      "2. 64\\sqrt{2}/3\n",
      "3. 104/3\n",
      "Answer: 3\n",
      "\n",
      "What is the greatest possible area of a triangular region with one vertex at the center of a circle of radius 1 and the other two vertices on the circle?\n",
      "Choose the best answer from the following options:\n",
      "0. 1/2\n",
      "1. 1\n",
      "2. sqrt(2)\n",
      "3. pi\n",
      "Answer: 0\n",
      "\n",
      "Sofia and Tess will each randomly choose one of the 10 integers from 1 to 10. What is the probability that neither integer chosen will be the square of the other?\n",
      "Choose the best answer from the following options:\n",
      "0. 0.64\n",
      "1. 0.72\n",
      "2. 0.81\n",
      "3. 0.95\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt, answer = gen_random_iccl_prompt({\"math\": [mmlu_math1, mmlu_math2, mmlu_math3]})\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multiple_iccl_prompts(topic_datasets, n_prompts):\n",
    "    \"\"\"\n",
    "    Generate multiple ICCL prompts for each topic with all possible orderings of easy/medium/hard demonstrations.\n",
    "    Creates 6 JSON files per topic (one for each possible ordering).\n",
    "    \n",
    "    Args:\n",
    "        topic_datasets: Dictionary of dataset triples {\"math\": [easy1, medium1, hard1], \"english\": [easy2, medium2, hard2], ...}\n",
    "                       where each dataset has a 'test' split\n",
    "        n_prompts: Number of prompts to generate per ordering\n",
    "    \"\"\"\n",
    "    # Get all possible orderings of demonstrations (1=easy, 2=medium, 3=hard)\n",
    "    orders = list(permutations([1, 2, 3]))\n",
    "    \n",
    "    for topic in topic_datasets:\n",
    "        # Create topic directory if it doesn't exist\n",
    "        os.makedirs(topic, exist_ok=True)\n",
    "        \n",
    "        easy_dataset, medium_dataset, hard_dataset = topic_datasets[topic]\n",
    "        \n",
    "        # Convert datasets to lists for easier random selection\n",
    "        easy_examples = list(easy_dataset['test'])\n",
    "        medium_examples = list(medium_dataset['test'])\n",
    "        hard_examples = list(hard_dataset['test'])\n",
    "        \n",
    "        # Track used hard examples across all orderings\n",
    "        used_hard_indices = set()\n",
    "        \n",
    "        # Generate the specified number of prompts\n",
    "        for prompt_idx in range(n_prompts):\n",
    "            # Select unused hard example for testing\n",
    "            available_hard_indices = [i for i in range(len(hard_examples)) if i not in used_hard_indices]\n",
    "            if not available_hard_indices:\n",
    "                raise ValueError(f\"Not enough unique hard examples available for topic {topic}\")\n",
    "            \n",
    "            test_hard_index = random.choice(available_hard_indices)\n",
    "            test_hard = hard_examples[test_hard_index]\n",
    "            used_hard_indices.add(test_hard_index)\n",
    "            \n",
    "            # Select demonstration examples\n",
    "            demo_easy = random.choice(easy_examples)\n",
    "            demo_medium = random.choice(medium_examples)\n",
    "            demo_hard = random.choice([ex for i, ex in enumerate(hard_examples) if i not in used_hard_indices])\n",
    "            \n",
    "            # For each possible ordering\n",
    "            for order in orders:\n",
    "                # Create prompts dict if it doesn't exist for this ordering\n",
    "                order_str = ''.join(str(x) for x in order)\n",
    "                filename = f\"{topic}_{order_str}_iccl_examples.json\"\n",
    "                filepath = os.path.join(topic, filename)\n",
    "                \n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        prompts = json.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    prompts = {}\n",
    "                \n",
    "                # Map order numbers to actual examples\n",
    "                order_to_example = {\n",
    "                    1: (demo_easy, \"easy\"),\n",
    "                    2: (demo_medium, \"medium\"),\n",
    "                    3: (demo_hard, \"hard\")\n",
    "                }\n",
    "                \n",
    "                # Generate demonstrations in specified order\n",
    "                demonstrations = []\n",
    "                for difficulty in order:\n",
    "                    example, level = order_to_example[difficulty]\n",
    "                    q, a = gen_iccl_single_example(example)\n",
    "                    demonstrations.append((q, a, level))\n",
    "                \n",
    "                # Generate test question\n",
    "                test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "                \n",
    "                # Build prompt\n",
    "                prompt = \"\"\n",
    "                for demo_q, demo_a, level in demonstrations:\n",
    "                    prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "                prompt += f\"{test_question}\"\n",
    "                \n",
    "                prompts[str(prompt_idx)] = {\n",
    "                    \"question\": prompt,\n",
    "                    \"answer\": test_answer,\n",
    "                }\n",
    "                \n",
    "                # Write prompts to JSON file\n",
    "                with open(filepath, 'w') as f:\n",
    "                    json.dump(prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_multiple_iccl_prompts({\"math\": [mmlu_math1, mmlu_math2, mmlu_math3]}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
