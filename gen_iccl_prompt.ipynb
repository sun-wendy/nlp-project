{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_math1 = load_dataset(\"cais/mmlu\", \"elementary_mathematics\")\n",
    "mmlu_math2 = load_dataset(\"cais/mmlu\", \"high_school_mathematics\")\n",
    "mmlu_math3 = load_dataset(\"cais/mmlu\", \"college_mathematics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Ms. Perez drove a total of 40 miles in 5 days. She drove the same number of miles each day. How many miles did Ms. Perez drive each day?', 'subject': 'elementary_mathematics', 'choices': ['5', '7', '8', '9'], 'answer': 2}\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset format\n",
    "print(mmlu_math1['test'][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ICCL prompts for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_iccl_single_example(example):\n",
    "    options = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    question = example['question'] + \"\\nChoose the best answer from the following options:\" + \"\\n\" + \"\\n\".join([f\"{options[i]}. {option}\" for i, option in enumerate(example['choices'])]) + \"\\nAnswer: \"\n",
    "    return question, example['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multiple_iccl_prompts(topic_dataset, topic, n_prompts, base_dir=\"./\"):\n",
    "    \"\"\"\n",
    "    Generate multiple ICCL prompts for a single topic with all possible orderings of demonstrations.\n",
    "    Creates JSON files for each possible ordering and a baseline file with hard questions only.\n",
    "    \n",
    "    Args:\n",
    "        topic_dataset: Dictionary with test splits {\"easy\": easy_dataset, \"medium\": medium_dataset, \"hard\": hard_dataset}\n",
    "        topic: String representing the topic, e.g. \"math\"\n",
    "        n_prompts: Number of prompts to generate per ordering\n",
    "    \"\"\"\n",
    "    # Get all possible orderings of demonstrations (1=easy, 2=medium, 3=hard)\n",
    "            # randoms = list(permutations([1, 2, 3]))\n",
    "    # if \"easy\" not in topic_dataset:\n",
    "    #     orders = [[1,2,3], [1,3,2],[3,1,2]]\n",
    "    \n",
    "    # Create topic directory if it doesn't exist\n",
    "    topic_dir = os.\n",
    "    os.makedirs(base_dir + topic, exist_ok=True)\n",
    "    \n",
    "    # Convert datasets to lists for easier random selection\n",
    "    if \"easy\" in topic_dataset:\n",
    "        easy_dataset = list(topic_dataset['easy']['test'])\n",
    "    medium_dataset = list(topic_dataset['medium']['test'])\n",
    "    hard_dataset = list(topic_dataset['hard']['test'])\n",
    "\n",
    "    randoms = list(permutations([1, 2, 3]))[1:] # exclude iccl\n",
    "    \n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Select demonstration examples that will be used across all orderings\n",
    "        if \"easy\" in topic_dataset:\n",
    "            demo_easy = random.choice(easy_dataset)\n",
    "            demo_medium = random.choice(medium_dataset)\n",
    "        else:\n",
    "            demo_easy, demo_medium = random.sample(medium_dataset, 2)\n",
    "        demo_hard = random.choice(hard_dataset)\n",
    "        test_hard = random.choice(hard_dataset)\n",
    "\n",
    "        orders = {\"iccl\": [1,2,3], \"random\": random.choice(randoms)} # choose random order \n",
    "        \n",
    "        # For each possible ordering\n",
    "        for order_str in orders:\n",
    "            # Create prompts dict if it doesn't exist for this ordering\n",
    "            order = orders[order_str]\n",
    "            \n",
    "            filename = f\"{topic}_{order_str}_examples.json\"\n",
    "            filepath = os.path.join(topic, filename)\n",
    "            \n",
    "            try:\n",
    "                with open(filepath, 'r') as f:\n",
    "                    prompts = json.load(f)\n",
    "            except FileNotFoundError:\n",
    "                prompts = {}\n",
    "            \n",
    "            # Map order numbers to actual examples\n",
    "            order_to_example = {\n",
    "                1: (demo_easy, \"easy\"),\n",
    "                2: (demo_medium, \"medium\"),\n",
    "                3: (demo_hard, \"hard\")\n",
    "            }\n",
    "            \n",
    "            # Generate demonstrations in specified order\n",
    "            demonstrations = []\n",
    "            for difficulty in order:\n",
    "                example, level = order_to_example[difficulty]\n",
    "                q, a = gen_iccl_single_example(example)\n",
    "                demonstrations.append((q, a, level))\n",
    "            \n",
    "            # Generate test question\n",
    "            test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "            \n",
    "            # Build prompt\n",
    "            prompt = \"\"\n",
    "            for demo_q, demo_a, level in demonstrations:\n",
    "                prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "            prompt += f\"{test_question}\"\n",
    "            \n",
    "            prompts[str(prompt_idx)] = {\n",
    "                \"question\": prompt,\n",
    "                \"answer\": test_answer,\n",
    "            }\n",
    "            \n",
    "            # Write prompts to JSON file\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(prompts, f, indent=4)\n",
    "            \n",
    "    ### HARD BASELINE: Generate baseline of hard-only prompts\n",
    "    baseline_filename = f\"{topic}_hard_baseline_iccl_examples.json\"\n",
    "    baseline_filepath = os.path.join(topic, baseline_filename)\n",
    "    baseline_prompts = {}\n",
    "    \n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Select two different hard questions for baseline\n",
    "        hard1, hard2 = random.sample(hard_dataset, 2)\n",
    "        q1, a1 = gen_iccl_single_example(hard1)\n",
    "        q2, a2 = gen_iccl_single_example(hard2)\n",
    "        \n",
    "        baseline_prompts[str(prompt_idx)] = {\n",
    "            \"question\": f\"{q1}{a1}\\n\\n{q2}\",\n",
    "            \"answer\": a2,\n",
    "        }\n",
    "    \n",
    "    #### Write baseline prompts to JSON file\n",
    "    with open(baseline_filepath, 'w') as f:\n",
    "        json.dump(baseline_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'math/math_iccl_examples.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m topics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiology\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchemistry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputer_science\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphysics\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m nicknames \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiology\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbio\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchemistry\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputer_science\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphysics\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphys\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 6\u001b[0m \u001b[43mgen_multiple_iccl_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43measy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmlu_math1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedium\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmlu_math2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmlu_math3\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./prompts/iccl_prompts/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 82\u001b[0m, in \u001b[0;36mgen_multiple_iccl_prompts\u001b[0;34m(topic_dataset, topic, n_prompts, base_dir)\u001b[0m\n\u001b[1;32m     76\u001b[0m         prompts[\u001b[38;5;28mstr\u001b[39m(prompt_idx)] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_answer,\n\u001b[1;32m     79\u001b[0m         }\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;66;03m# Write prompts to JSON file\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     83\u001b[0m             json\u001b[38;5;241m.\u001b[39mdump(prompts, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m### HARD BASELINE: Generate baseline of hard-only prompts\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'math/math_iccl_examples.json'"
     ]
    }
   ],
   "source": [
    "n_prompts = 50\n",
    "\n",
    "topics = [\"biology\", \"chemistry\", \"computer_science\", \"physics\"]\n",
    "nicknames = {\"biology\": \"bio\", \"chemistry\":\"chem\", \"computer_science\": \"cs\", \"physics\": \"phys\"}\n",
    "\n",
    "gen_multiple_iccl_prompts({\"easy\": mmlu_math1, \"medium\": mmlu_math2, \"hard\": mmlu_math3}, \"math\", 50, \"./prompts/iccl_prompts/\")\n",
    "\n",
    "# for topic in topics:\n",
    "#     mmlu_1 = load_dataset(\"cais/mmlu\", f\"high_school_{topic}\")\n",
    "#     mmlu_2 = load_dataset(\"cais/mmlu\", f\"college_{topic}\")\n",
    "    \n",
    "#     topic_dataset = {\"medium\": mmlu_1, \"hard\": mmlu_2}\n",
    "#     gen_multiple_iccl_prompts(topic_dataset, nicknames[topic], 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train/test split for maggie/jennifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def split_and_save_datasets(topic_dataset, topic, output_dir: str = \"./\"):\n",
    "    \"\"\"\n",
    "    Split datasets into train and test sets and save them as JSON files.\n",
    "    \n",
    "    Args:\n",
    "        topic_dataset: Dictionary with 'medium' and 'hard' datasets\n",
    "        output_dir: Directory to save the JSON files\n",
    "    \"\"\"\n",
    "    train_dir = os.path.join(output_dir, \"train\", topic)\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Ensure we're working with the train split if it's a DatasetDict\n",
    "    medium_data = topic_dataset['medium']['test']\n",
    "    hard_data = topic_dataset['hard']['test']\n",
    "    \n",
    "    # Convert to list of dictionaries for easier handling\n",
    "    medium_list = medium_data.to_list()\n",
    "    hard_list = hard_data.to_list()\n",
    "    \n",
    "    # Randomly shuffle the data\n",
    "    random.shuffle(medium_list)\n",
    "    random.shuffle(hard_list)\n",
    "    \n",
    "    # Split the datasets\n",
    "    train_medium = medium_list[:100]  # First 100 for medium training\n",
    "    train_hard = hard_list[:50]       # First 50 for hard training\n",
    "    test_hard = hard_list[50:100]     # Next 50 for hard testing\n",
    "    \n",
    "    # Create combined training set\n",
    "    combined_train = deepcopy(train_medium) + deepcopy(train_hard)\n",
    "    shuffled_train = deepcopy(combined_train)\n",
    "    random.shuffle(shuffled_train)\n",
    "\n",
    "    ### JUST FOR MATH - comment out otherwise\n",
    "    # easy_data = topic_dataset['easy']['test']\n",
    "    # easy_list = easy_data.to_list()\n",
    "    # random.shuffle(easy_list)\n",
    "    # train_easy = easy_list[:50]\n",
    "    # train_medium = train_medium[:50]\n",
    "    # combined_train = deepcopy(train_easy) + deepcopy(train_medium) + deepcopy(train_hard)\n",
    "    # shuffled_train = deepcopy(combined_train)\n",
    "    # random.shuffle(shuffled_train)\n",
    "    \n",
    "   \n",
    "\n",
    "    # Save training files\n",
    "    train_files = {\n",
    "        'medium.json': train_medium,\n",
    "        'hard.json': train_hard,\n",
    "        'shuffled.json': shuffled_train,\n",
    "        'concat.json': combined_train\n",
    "    }\n",
    "\n",
    "    ### comment out later\n",
    "    # train_files['easy.json'] = train_easy\n",
    "    \n",
    "    test_files = {\n",
    "        f'{topic}.json': train_hard,\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    datasets = ((train_files, train_dir), (test_files, test_dir))\n",
    "\n",
    "    for dataset, dataset_dir in datasets:\n",
    "        \n",
    "        \n",
    "        for filename, data in dataset.items():\n",
    "            reformatted_data = []\n",
    "            for elt in data:\n",
    "                test_question, test_answer = gen_iccl_single_example(elt)\n",
    "                reformatted_data.append({\"question\": test_question, \"answer\": test_answer})\n",
    "    \n",
    "            data = reformatted_data\n",
    "            \n",
    "            \n",
    "            full_path = os.path.join(dataset_dir, filename)\n",
    "            with open(full_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Saved {len(data)} examples to {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 examples to ./maggie_jennifer/train/bio/medium.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/bio/hard.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/bio/shuffled.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/bio/concat.json\n",
      "Saved 50 examples to ./maggie_jennifer/test/bio.json\n",
      "Saved 100 examples to ./maggie_jennifer/train/chem/medium.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/chem/hard.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/chem/shuffled.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/chem/concat.json\n",
      "Saved 50 examples to ./maggie_jennifer/test/chem.json\n",
      "Saved 100 examples to ./maggie_jennifer/train/cs/medium.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/cs/hard.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/cs/shuffled.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/cs/concat.json\n",
      "Saved 50 examples to ./maggie_jennifer/test/cs.json\n",
      "Saved 100 examples to ./maggie_jennifer/train/phys/medium.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/phys/hard.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/phys/shuffled.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/phys/concat.json\n",
      "Saved 50 examples to ./maggie_jennifer/test/phys.json\n"
     ]
    }
   ],
   "source": [
    "n_prompts = 50\n",
    "\n",
    "topics = [\"biology\", \"chemistry\", \"computer_science\", \"physics\"]\n",
    "nicknames = {\"biology\": \"bio\", \"chemistry\":\"chem\", \"computer_science\": \"cs\", \"physics\": \"phys\"}\n",
    "\n",
    "# Create directory structure\n",
    "train_dir = os.path.join(\"./maggie_jennifer\", \"train\")\n",
    "test_dir = os.path.join(\"./maggie_jennifer\", \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for topic in topics:\n",
    "    mmlu_1 = load_dataset(\"cais/mmlu\", f\"high_school_{topic}\")\n",
    "    mmlu_2 = load_dataset(\"cais/mmlu\", f\"college_{topic}\")\n",
    "    \n",
    "    topic_dataset = {\"medium\": mmlu_1, \"hard\": mmlu_2}\n",
    "    split_and_save_datasets(topic_dataset, nicknames[topic], \"./maggie_jennifer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 examples to ./maggie_jennifer/train/math/medium.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/math/hard.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/math/shuffled.json\n",
      "Saved 150 examples to ./maggie_jennifer/train/math/concat.json\n",
      "Saved 50 examples to ./maggie_jennifer/train/math/easy.json\n",
      "Saved 50 examples to ./maggie_jennifer/test/math.json\n"
     ]
    }
   ],
   "source": [
    "topic = \"mathematics\"\n",
    "mmlu_0 = load_dataset(\"cais/mmlu\", f\"elementary_{topic}\")\n",
    "mmlu_1 = load_dataset(\"cais/mmlu\", f\"high_school_{topic}\")\n",
    "mmlu_2 = load_dataset(\"cais/mmlu\", f\"college_{topic}\")\n",
    "\n",
    "split_and_save_datasets({\"easy\": mmlu_0, \"medium\": mmlu_1, \"hard\": mmlu_2}, \"math\", \"./maggie_jennifer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multiple_iccl_prompts(topic_datasets, n_prompts):\n",
    "    \"\"\"\n",
    "    Generate multiple ICCL prompts for each topic with all possible orderings of easy/medium/hard demonstrations.\n",
    "    Creates 6 JSON files per topic (one for each possible ordering).\n",
    "    \n",
    "    Args:\n",
    "        topic_datasets: Dictionary of dataset triples {\"math\": [easy1, medium1, hard1], \"english\": [easy2, medium2, hard2], ...}\n",
    "                       where each dataset has a 'test' split\n",
    "        n_prompts: Number of prompts to generate per ordering\n",
    "    \"\"\"\n",
    "    # Get all possible orderings of demonstrations (1=easy, 2=medium, 3=hard)\n",
    "    orders = list(permutations([1, 2, 3]))\n",
    "    \n",
    "    for topic in topic_datasets:\n",
    "        # Create topic directory if it doesn't exist\n",
    "        os.makedirs(topic, exist_ok=True)\n",
    "        \n",
    "        easy_dataset, medium_dataset, hard_dataset = topic_datasets[topic]\n",
    "        \n",
    "        # Convert datasets to lists for easier random selection\n",
    "        easy_examples = list(easy_dataset['test'])\n",
    "        medium_examples = list(medium_dataset['test'])\n",
    "        hard_examples = list(hard_dataset['test'])\n",
    "        \n",
    "        # Track used hard examples across all orderings\n",
    "        used_hard_indices = set()\n",
    "        \n",
    "        # Generate the specified number of prompts\n",
    "        for prompt_idx in range(n_prompts):\n",
    "            # Select unused hard example for testing\n",
    "            available_hard_indices = [i for i in range(len(hard_examples)) if i not in used_hard_indices]\n",
    "            if not available_hard_indices:\n",
    "                raise ValueError(f\"Not enough unique hard examples available for topic {topic}\")\n",
    "            \n",
    "            test_hard_index = random.choice(available_hard_indices)\n",
    "            test_hard = hard_examples[test_hard_index]\n",
    "            used_hard_indices.add(test_hard_index)\n",
    "            \n",
    "            # Select demonstration examples\n",
    "            demo_easy = random.choice(easy_examples)\n",
    "            demo_medium = random.choice(medium_examples)\n",
    "            demo_hard = random.choice([ex for i, ex in enumerate(hard_examples) if i not in used_hard_indices])\n",
    "            \n",
    "            # For each possible ordering\n",
    "            for order in orders:\n",
    "                # Create prompts dict if it doesn't exist for this ordering\n",
    "                order_str = ''.join(str(x) for x in order)\n",
    "                filename = f\"{topic}_{order_str}_iccl_examples.json\"\n",
    "                filepath = os.path.join(topic, filename)\n",
    "                \n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        prompts = json.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    prompts = {}\n",
    "                \n",
    "                # Map order numbers to actual examples\n",
    "                order_to_example = {\n",
    "                    1: (demo_easy, \"easy\"),\n",
    "                    2: (demo_medium, \"medium\"),\n",
    "                    3: (demo_hard, \"hard\")\n",
    "                }\n",
    "                \n",
    "                # Generate demonstrations in specified order\n",
    "                demonstrations = []\n",
    "                for difficulty in order:\n",
    "                    example, level = order_to_example[difficulty]\n",
    "                    q, a = gen_iccl_single_example(example)\n",
    "                    demonstrations.append((q, a, level))\n",
    "                \n",
    "                # Generate test question\n",
    "                test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "                \n",
    "                # Build prompt\n",
    "                prompt = \"\"\n",
    "                for demo_q, demo_a, level in demonstrations:\n",
    "                    prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "                prompt += f\"{test_question}\"\n",
    "                \n",
    "                prompts[str(prompt_idx)] = {\n",
    "                    \"question\": prompt,\n",
    "                    \"answer\": test_answer,\n",
    "                }\n",
    "                \n",
    "                # Write prompts to JSON file\n",
    "                with open(filepath, 'w') as f:\n",
    "                    json.dump(prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_iccl_prompt(topic_datasets):\n",
    "    \"\"\"\n",
    "    Generate a random ICCL prompt with demonstrations from easy/medium/hard difficulty,\n",
    "    followed by a hard test question.\n",
    "    \n",
    "    Args:\n",
    "        topic_datasets: Dictionary of dataset triples {\"math\": [easy1, medium1, hard1], \"english\": [easy2, medium2, hard2], ...}\n",
    "                       where each dataset has a 'test' split\n",
    "    \n",
    "    Returns:\n",
    "        str: prompt_string\n",
    "    \"\"\"\n",
    "    # Randomly select a topic\n",
    "    topic = random.choice(list(topic_datasets.keys()))\n",
    "    easy_dataset, medium_dataset, hard_dataset = topic_datasets[topic]\n",
    "    \n",
    "    # Convert datasets to lists for easier random selection\n",
    "    easy_examples = list(easy_dataset['test'])\n",
    "    medium_examples = list(medium_dataset['test'])\n",
    "    hard_examples = list(hard_dataset['test'])\n",
    "    \n",
    "    # Select demonstration examples\n",
    "    demo_easy = random.choice(easy_examples)\n",
    "    demo_medium = random.choice(medium_examples)\n",
    "    demo_hard = random.choice(hard_examples)\n",
    "    \n",
    "    # Select test example from remaining hard examples\n",
    "    # Ensure we don't use the same hard example as in demonstration\n",
    "    remaining_hard = [ex for ex in hard_examples if ex != demo_hard]\n",
    "    if not remaining_hard:\n",
    "        raise ValueError(\"Not enough unique hard examples available\")\n",
    "    test_hard = random.choice(remaining_hard)\n",
    "    \n",
    "    # Generate demonstrations\n",
    "    demonstrations = [\n",
    "        gen_iccl_single_example(demo_easy),\n",
    "        gen_iccl_single_example(demo_medium),\n",
    "        gen_iccl_single_example(demo_hard)\n",
    "    ]\n",
    "    \n",
    "    # Generate test question, won't return test_answer\n",
    "    test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = \"\"\n",
    "    for demo_q, demo_a in demonstrations:\n",
    "        prompt += f\"{demo_q}{demo_a}\\n\\n\"\n",
    "    prompt += f\"{test_question}\"\n",
    "    \n",
    "    return prompt, test_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gwen wrote the number pattern below on a piece of paper. 1, 5, 9, 13 What are the next two terms in Gwenâ€™s pattern?\n",
      "Choose the best answer from the following options:\n",
      "0. 15, 17\n",
      "1. 15, 19\n",
      "2. 17, 19\n",
      "3. 17, 21\n",
      "Answer: 3\n",
      "\n",
      "The area bounded by the parabola y = x^2 and the lines y = 1 and y = 9 equals\n",
      "Choose the best answer from the following options:\n",
      "0. 8\n",
      "1. 84/3\n",
      "2. 64\\sqrt{2}/3\n",
      "3. 104/3\n",
      "Answer: 3\n",
      "\n",
      "What is the greatest possible area of a triangular region with one vertex at the center of a circle of radius 1 and the other two vertices on the circle?\n",
      "Choose the best answer from the following options:\n",
      "0. 1/2\n",
      "1. 1\n",
      "2. sqrt(2)\n",
      "3. pi\n",
      "Answer: 0\n",
      "\n",
      "Sofia and Tess will each randomly choose one of the 10 integers from 1 to 10. What is the probability that neither integer chosen will be the square of the other?\n",
      "Choose the best answer from the following options:\n",
      "0. 0.64\n",
      "1. 0.72\n",
      "2. 0.81\n",
      "3. 0.95\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt, answer = gen_random_iccl_prompt({\"math\": [mmlu_math1, mmlu_math2, mmlu_math3]})\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_multiple_iccl_prompts({\"math\": [mmlu_math1, mmlu_math2, mmlu_math3]}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test on math subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_iccl_single_example(example):\n",
    "    options = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    question = example['question'] + \"\\nChoose the best answer from the following options:\" + \"\\n\" + \"\\n\".join([f\"{options[i]}. {option}\" for i, option in enumerate(example['choices'])]) + \"\\nAnswer: \"\n",
    "    return question, example['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the value of p in 24 = 2p?\n",
      "Choose the best answer from the following options:\n",
      "A. p = 4\n",
      "B. p = 8\n",
      "C. p = 12\n",
      "D. p = 24\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(gen_iccl_single_example(mmlu_math1['test'][0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_all_iccl_prompts(easy_dataset, medium_dataset, hard_dataset, n_prompts, topic):\n",
    "    try:\n",
    "        with open(\"iccl_prompts.json\", 'r') as f:\n",
    "            iccl_prompts = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        iccl_prompts = {}\n",
    "    if topic not in iccl_prompts:\n",
    "        iccl_prompts[topic] = {}\n",
    "    \n",
    "    # Convert datasets to lists for easier shuffling & tracking\n",
    "    easy_examples = list(easy_dataset['test'])\n",
    "    medium_examples = list(medium_dataset['test'])\n",
    "    hard_examples = list(hard_dataset['test'])\n",
    "\n",
    "    # Use indices to track used hard examples\n",
    "    used_hard_indices = set()\n",
    "    prompts = []\n",
    "    for prompt_idx in range(n_prompts):\n",
    "        # Curriculum examples for demonstrations\n",
    "        demo_easy = random.choice(easy_examples)\n",
    "        demo_medium = random.choice(medium_examples)\n",
    "        demo_hard_index = random.choice([i for i in range(len(hard_examples)) if i not in used_hard_indices])\n",
    "        demo_hard = hard_examples[demo_hard_index]\n",
    "\n",
    "        # Can't use hard example that appeared in demonstration for testing\n",
    "        used_hard_indices.add(demo_hard_index)\n",
    "        available_hard_indices = [i for i in range(len(hard_examples)) if i not in used_hard_indices]\n",
    "        if not available_hard_indices:\n",
    "            raise ValueError(\"Not enough unique hard examples available\")\n",
    "        test_hard_index = random.choice(available_hard_indices)\n",
    "        test_hard = hard_examples[test_hard_index]\n",
    "        used_hard_indices.add(test_hard_index)\n",
    "\n",
    "        demonstrations = [\n",
    "            gen_iccl_single_example(demo_easy),\n",
    "            gen_iccl_single_example(demo_medium),\n",
    "            gen_iccl_single_example(demo_hard)\n",
    "        ]\n",
    "        test_question, test_answer = gen_iccl_single_example(test_hard)\n",
    "\n",
    "        prompt = \"\"\n",
    "        for demo_q, demo_a in demonstrations:\n",
    "            prompt += f\"{demo_q}\" + str(demo_a) + \"\\n\\n\"\n",
    "        prompt += f\"{test_question}\"\n",
    "\n",
    "        iccl_prompts[topic][f\"{prompt_idx}\"] = {\n",
    "            \"question\": prompt,\n",
    "            \"answer\": test_answer\n",
    "        }\n",
    "\n",
    "    # Write the updated JSON back to the file\n",
    "    with open(\"iccl_prompts.json\", 'w') as f:\n",
    "        json.dump(iccl_prompts, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_all_iccl_prompts(mmlu_math1, mmlu_math2, mmlu_math3, int(len(mmlu_math3['test']) // 2), \"math\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
